## Description

The model trained in this demo is used to classify images of "rock", "paper" and "scissor" hand gestures. The input size is 64x64 pixels RGB which is 3x64x64 in CHW format.

The code is auto-generated by the ai8x-synthesis tool and runs a known-answer
test with a pre-defined input sample. The enhanced version of this example with live capture and TFT
output is located in "rps-demo: directory.

## Setup

##### Building Firmware: 

Before building firmware you must select the correct value for _BOARD_  in "project.mk", either "EvKit\_V1" or "FTHR\_RevA", depending on the EV kit you are using to run the example.

After doing so, navigate to the directory where the example is located using a terminal window. Enter the following comand to build all of the files needed to run the example.

```
$ make
```

##### Required Connections:

If using the standard EV Kit (EvKit_V1):
-   Connect a USB cable between the PC and the CN1 (USB/PWR) connector.
-   Connect pins 1 and 2 (P0_1) of the JH1 (UART 0 EN) header.
-   Open a terminal application on the PC and connect to the EV kit's console UART at 115200, 8-N-1.

If using the Featherboard (FTHR_RevA):
-   Connect a USB cable between the PC and the CN1 (USB/PWR) connector.
-   Open a terminal application on the PC and connect to the EV kit's console UART at 115200, 8-N-1.

## Expected Output

The Console UART of the device will output these messages:

```
Waiting...

*** CNN Inference Test ***

*** PASS ***

Approximate data loading and inference time: 4252 us

Classification results:
[ 498738] -> Class 0: 100.0%
[-334218] -> Class 1: 0.0%
[-632906] -> Class 2: 0.0%
```

